{
  "permissions": {
    "allow": [
      "mcp__ide__executeCode",
      "Bash(python:*)",
      "Bash(pip install:*)",
      "Bash(conda list:*)",
      "Bash(recitation1Scriptsactivate)",
      "Bash(.recitation1Scriptsactivate)",
      "Bash(call recitation1Scriptsactivate.bat)",
      "Bash(.recitation1Scriptspip.exe install pandas numpy matplotlib scikit-learn tensorly jupyter)",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\pip.exe\" install pandas numpy matplotlib scikit-learn tensorly jupyter)",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" -c \"\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use(''Agg'')  # Use non-GUI backend\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple, Optional\nimport warnings\nwarnings.filterwarnings(''ignore'')\n\nprint(''✓ All basic imports successful'')\n\n# Test data loading\ntry:\n    full_df = pd.read_csv(''recitations_data_electricity_demand_timeseries.csv'', index_col=0, parse_dates=True)\n    print(f''✓ Data loaded successfully: {full_df.shape}'')\n    print(f''✓ Columns available: {len(full_df.columns)}'')\n    print(f''✓ Target column MT_370 present: {\"\"MT_370\"\" in full_df.columns}'')\nexcept Exception as e:\n    print(f''✗ Data loading failed: {e}'')\n\n# Test core mathematical functions\ndef create_page_matrix(ts, L):\n    T = len(ts)\n    page_matrix = np.zeros((L, T // L))\n    for t in range(min(T, L * (T // L))):\n        i = t % L\n        j = t // L\n        page_matrix[i, j] = ts[t]\n    return page_matrix\n\n# Test page matrix creation\ntest_ts = np.arange(12)\nL = 3\npage_mat = create_page_matrix(test_ts, L)\nprint(f''✓ Page matrix creation successful, shape: {page_mat.shape}'')\n\n# Test SVD\nU, s, Vh = np.linalg.svd(page_mat, full_matrices=False)\nprint(f''✓ SVD decomposition successful, ranks: {len(s)}'')\n\nprint(''✓ All core functionality tests passed!'')\n\")",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" -c \"\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use(''Agg'')  # Use non-GUI backend\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple, Optional\nimport warnings\nwarnings.filterwarnings(''ignore'')\n\nprint(''All basic imports successful'')\n\n# Test data loading\ntry:\n    full_df = pd.read_csv(''recitations_data_electricity_demand_timeseries.csv'', index_col=0, parse_dates=True)\n    print(''Data loaded successfully:'', full_df.shape)\n    print(''Columns available:'', len(full_df.columns))\n    print(''Target column MT_370 present:'', ''MT_370'' in full_df.columns)\nexcept Exception as e:\n    print(''Data loading failed:'', e)\n\n# Test core mathematical functions\ndef create_page_matrix(ts, L):\n    T = len(ts)\n    page_matrix = np.zeros((L, T // L))\n    for t in range(min(T, L * (T // L))):\n        i = t % L\n        j = t // L\n        page_matrix[i, j] = ts[t]\n    return page_matrix\n\n# Test page matrix creation\ntest_ts = np.arange(12)\nL = 3\npage_mat = create_page_matrix(test_ts, L)\nprint(''Page matrix creation successful, shape:'', page_mat.shape)\n\n# Test SVD\nU, s, Vh = np.linalg.svd(page_mat, full_matrices=False)\nprint(''SVD decomposition successful, ranks:'', len(s))\n\n# Test tensorly import\ntry:\n    import tensorly as tl\n    from tensorly.decomposition import parafac\n    print(''Tensorly import successful'')\nexcept ImportError as e:\n    print(''Tensorly import failed:'', e)\n\nprint(''All core functionality tests passed!'')\n\")",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" -c \"\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use(''Agg'')\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple, Optional\nimport warnings\nwarnings.filterwarnings(''ignore'')\n\n# Configuration parameters\nCONFIG = {\n    ''data_file'': ''recitations_data_electricity_demand_timeseries.csv'',\n    ''target_column'': ''MT_370'',\n    ''train_size'': 132**2,  # T = 17424\n    ''test_size'': 24,\n    ''ssa_window_size'': 132,\n    ''energy_threshold'': 0.99,\n    ''random_seed'': 42\n}\n\nnp.random.seed(CONFIG[''random_seed''])\n\n# Load and split data\ndef load_and_split_data(file_path, target_column, train_size, test_size):\n    full_df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n    train_data = full_df.iloc[:train_size, :]\n    test_data = full_df.iloc[train_size:train_size + test_size, :]\n    return full_df, train_data, test_data\n\nfull_df, train_data, test_data = load_and_split_data(\n    CONFIG[''data_file''], CONFIG[''target_column''], \n    CONFIG[''train_size''], CONFIG[''test_size'']\n)\n\nprint(''Data loaded and split successfully'')\nprint(''Full dataset shape:'', full_df.shape)\nprint(''Training data shape:'', train_data.shape)\nprint(''Test data shape:'', test_data.shape)\n\n# Test core SSA functions\ndef create_page_matrix(ts, L):\n    T = len(ts)\n    page_matrix = np.zeros((L, T // L))\n    for t in range(min(T, L * (T // L))):\n        i = t % L\n        j = t // L\n        page_matrix[i, j] = ts[t]\n    return page_matrix\n\ndef select_rank_by_energy(singular_values, threshold=0.99):\n    cumulative_energy = np.cumsum(singular_values**2) / np.sum(singular_values**2)\n    r = np.argmax(cumulative_energy >= threshold) + 1\n    return min(r, len(singular_values))\n\n# Test SSA on a small sample\nts = train_data[CONFIG[''target_column'']].fillna(0).to_numpy()\nL = CONFIG[''ssa_window_size'']\n\nprint(''Creating page matrix...'')\npage_matrix = create_page_matrix(ts, L)\nprint(''Page matrix shape:'', page_matrix.shape)\n\nprint(''Performing SVD...'')\nU, s, Vh = np.linalg.svd(page_matrix, full_matrices=False)\nrank = select_rank_by_energy(s, CONFIG[''energy_threshold''])\nprint(''Selected rank:'', rank, ''out of'', len(s), ''components'')\n\nprint(''SSA core functionality test completed successfully!'')\n\")",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" -c \"\n# Complete notebook test - SSA Method\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use(''Agg'')\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple, Optional\nimport warnings\nwarnings.filterwarnings(''ignore'')\n\n# Configuration\nCONFIG = {\n    ''data_file'': ''recitations_data_electricity_demand_timeseries.csv'',\n    ''target_column'': ''MT_370'',\n    ''train_size'': 132**2,\n    ''test_size'': 24,\n    ''ssa_window_size'': 132,\n    ''energy_threshold'': 0.99,\n    ''random_seed'': 42\n}\n\nnp.random.seed(CONFIG[''random_seed''])\n\n# Load data\ndef load_and_split_data(file_path, target_column, train_size, test_size):\n    full_df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n    train_data = full_df.iloc[:train_size, :]\n    test_data = full_df.iloc[train_size:train_size + test_size, :]\n    return full_df, train_data, test_data\n\nfull_df, train_data, test_data = load_and_split_data(\n    CONFIG[''data_file''], CONFIG[''target_column''], \n    CONFIG[''train_size''], CONFIG[''test_size'']\n)\n\nprint(''=== SSA FORECASTING TEST ==='')\n\n# Core SSA functions\ndef create_page_matrix(ts, L):\n    T = len(ts)\n    page_matrix = np.zeros((L, T // L))\n    for t in range(min(T, L * (T // L))):\n        i = t % L\n        j = t // L\n        page_matrix[i, j] = ts[t]\n    return page_matrix\n\ndef select_rank_by_energy(singular_values, threshold=0.99):\n    cumulative_energy = np.cumsum(singular_values**2) / np.sum(singular_values**2)\n    r = np.argmax(cumulative_energy >= threshold) + 1\n    return min(r, len(singular_values))\n\ndef perform_svd_truncation(matrix, rank, rho_hat):\n    U, s, Vh = np.linalg.svd(matrix, full_matrices=False)\n    U_r = U[:, :rank]\n    s_r = s[:rank]\n    Vh_r = Vh[:rank, :]\n    denoised_matrix = (U_r @ np.diag(s_r) @ Vh_r) / rho_hat\n    return denoised_matrix\n\ndef learn_prediction_coefficients(denoised_matrix, original_matrix):\n    Phi = denoised_matrix[:-1, :].T\n    Y = original_matrix[-1, :]\n    betas = np.linalg.pinv(Phi) @ Y\n    return betas\n\ndef generate_forecasts(betas, full_ts, train_length, test_length, window_size, test_index):\n    forecasts = []\n    for t in range(train_length, train_length + test_length):\n        if t >= window_size - 1:\n            forecast_window = full_ts[t - window_size + 1:t]\n            if len(forecast_window) == len(betas):\n                forecast = np.dot(betas, forecast_window)\n            else:\n                forecast = np.nan\n            forecasts.append(forecast)\n        else:\n            forecasts.append(np.nan)\n    return pd.Series(forecasts, index=test_index)\n\n# Run SSA\nnull_idx = train_data[CONFIG[''target_column'']].isna()\nrho_hat = 1 - (null_idx.sum() / len(train_data))\nts = train_data[CONFIG[''target_column'']].fillna(0).to_numpy()\n\nprint(''Missing data ratio:'', 1 - rho_hat)\nprint(''Window size (L):'', CONFIG[''ssa_window_size''])\n\n# Create page matrix\npage_matrix = create_page_matrix(ts, CONFIG[''ssa_window_size''])\nprint(''Page matrix shape:'', page_matrix.shape)\n\n# SVD and rank selection\nU, s, Vh = np.linalg.svd(page_matrix, full_matrices=False)\nrank = select_rank_by_energy(s, CONFIG[''energy_threshold''])\nprint(''Selected rank r:'', rank)\n\n# Denoise matrix\ndenoised_matrix = perform_svd_truncation(page_matrix, rank, rho_hat)\n\n# Learn coefficients\nbetas = learn_prediction_coefficients(denoised_matrix, page_matrix)\nprint(''Beta coefficients shape:'', betas.shape)\n\n# Generate forecasts\nfull_ts = full_df[CONFIG[''target_column'']].fillna(0).to_numpy()\nforecasts = generate_forecasts(betas, full_ts, len(train_data), \n                             len(test_data), CONFIG[''ssa_window_size''], test_data.index)\n\nprint(''Forecasts generated successfully'')\nprint(''Forecast shape:'', forecasts.shape)\nprint(''Number of valid forecasts:'', (~forecasts.isna()).sum())\n\n# Calculate MSE\nactual = test_data[CONFIG[''target_column'']]\nvalid_mask = ~(actual.isna() | forecasts.isna())\nif valid_mask.sum() > 0:\n    mse = np.mean((actual[valid_mask] - forecasts[valid_mask]) ** 2)\n    print(''SSA MSE:'', mse)\nelse:\n    print(''No valid forecasts for MSE calculation'')\n\nprint(''SSA method completed successfully!'')\n\")",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" -c \"\n# Complete notebook test - SSA Method\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use(''Agg'')\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple, Optional\nimport warnings\nwarnings.filterwarnings(''ignore'')\n\n# Configuration\nCONFIG = {\n    ''data_file'': ''recitations_data_electricity_demand_timeseries.csv'',\n    ''target_column'': ''MT_370'',\n    ''train_size'': 132**2,\n    ''test_size'': 24,\n    ''ssa_window_size'': 132,\n    ''energy_threshold'': 0.99,\n    ''random_seed'': 42\n}\n\nnp.random.seed(CONFIG[''random_seed''])\n\n# Load data\ndef load_and_split_data(file_path, target_column, train_size, test_size):\n    full_df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n    train_data = full_df.iloc[:train_size, :]\n    test_data = full_df.iloc[train_size:train_size + test_size, :]\n    return full_df, train_data, test_data\n\nfull_df, train_data, test_data = load_and_split_data(\n    CONFIG[''data_file''], CONFIG[''target_column''], \n    CONFIG[''train_size''], CONFIG[''test_size'']\n)\n\nprint(''=== SSA FORECASTING TEST ==='')\n\n# Core SSA functions\ndef create_page_matrix(ts, L):\n    T = len(ts)\n    page_matrix = np.zeros((L, T // L))\n    for t in range(min(T, L * (T // L))):\n        i = t % L\n        j = t // L\n        page_matrix[i, j] = ts[t]\n    return page_matrix\n\ndef select_rank_by_energy(singular_values, threshold=0.99):\n    cumulative_energy = np.cumsum(singular_values**2) / np.sum(singular_values**2)\n    r = np.argmax(cumulative_energy >= threshold) + 1\n    return min(r, len(singular_values))\n\ndef perform_svd_truncation(matrix, rank, rho_hat):\n    U, s, Vh = np.linalg.svd(matrix, full_matrices=False)\n    U_r = U[:, :rank]\n    s_r = s[:rank]\n    Vh_r = Vh[:rank, :]\n    denoised_matrix = (U_r @ np.diag(s_r) @ Vh_r) / rho_hat\n    return denoised_matrix\n\ndef learn_prediction_coefficients(denoised_matrix, original_matrix):\n    Phi = denoised_matrix[:-1, :].T\n    Y = original_matrix[-1, :]\n    betas = np.linalg.pinv(Phi) @ Y\n    return betas\n\ndef generate_forecasts(betas, full_ts, train_length, test_length, window_size, test_index):\n    forecasts = []\n    for t in range(train_length, train_length + test_length):\n        if t >= window_size - 1:\n            forecast_window = full_ts[t - window_size + 1:t]\n            if len(forecast_window) == len(betas):\n                forecast = np.dot(betas, forecast_window)\n            else:\n                forecast = np.nan\n            forecasts.append(forecast)\n        else:\n            forecasts.append(np.nan)\n    return pd.Series(forecasts, index=test_index)\n\n# Run SSA\nnull_idx = train_data[CONFIG[''target_column'']].isna()\nrho_hat = 1 - (null_idx.sum() / len(train_data))\nts = train_data[CONFIG[''target_column'']].fillna(0).to_numpy()\n\nprint(''Missing data ratio:'', 1 - rho_hat)\nprint(''Window size (L):'', CONFIG[''ssa_window_size''])\n\n# Create page matrix\npage_matrix = create_page_matrix(ts, CONFIG[''ssa_window_size''])\nprint(''Page matrix shape:'', page_matrix.shape)\n\n# SVD and rank selection\nU, s, Vh = np.linalg.svd(page_matrix, full_matrices=False)\nrank = select_rank_by_energy(s, CONFIG[''energy_threshold''])\nprint(''Selected rank r:'', rank)\n\n# Denoise matrix\ndenoised_matrix = perform_svd_truncation(page_matrix, rank, rho_hat)\n\n# Learn coefficients\nbetas = learn_prediction_coefficients(denoised_matrix, page_matrix)\nprint(''Beta coefficients shape:'', betas.shape)\n\n# Generate forecasts\nfull_ts = full_df[CONFIG[''target_column'']].fillna(0).to_numpy()\nforecasts = generate_forecasts(betas, full_ts, len(train_data), \n                             len(test_data), CONFIG[''ssa_window_size''], test_data.index)\n\nprint(''Forecasts generated successfully'')\nprint(''Forecast shape:'', forecasts.shape)\nprint(''Number of valid forecasts:'', (~forecasts.isna()).sum())\n\n# Calculate MSE\nactual = test_data[CONFIG[''target_column'']]\nvalid_mask = ~(actual.isna() | forecasts.isna())\nif valid_mask.sum() > 0:\n    mse = np.mean((actual[valid_mask] - forecasts[valid_mask]) ** 2)\n    print(''SSA MSE:'', mse)\nelse:\n    print(''No valid forecasts for MSE calculation'')\n\nprint(''SSA method completed successfully!'')\n\")",
      "Bash(.recitation1Scriptspython.exe test_ssa.py)",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" \"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\test_ssa.py\")",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" \"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\test_mssa.py\")",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" \"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\test_tssa.py\")",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" \"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\test_all_methods.py\")",
      "Bash(del:*)",
      "Bash(rm:*)",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\python.exe\" \"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\run_complete_notebook.py\")",
      "Bash(start \"\" \"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\jupyter.exe\" notebook --notebook-dir=\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\")",
      "Bash(\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\\recitation1\\Scripts\\jupyter.exe\" notebook --notebook-dir=\"C:\\Users\\MR-BEST\\MMSDS\\t-series\\module_2\\citations\" --no-browser)",
      "Bash(git remote set-url:*)",
      "Bash(ls:*)",
      "Bash(git init:*)",
      "Bash(git remote add:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git push:*)",
      "Bash(gh:*)",
      "Bash(mkdir:*)",
      "Bash(mv:*)"
    ],
    "deny": []
  }
}